{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 1.1\n",
    "Self-Play:\n",
    "This is what Alpha Zero was trained. In this case, I think the agent will improve itself in terms of both attacking and defense strategies by self-corrections. It will learn a different policy as the opponent is now itself with a different way of playing. Eventually, when the agent becomes much better, the game will most likely lead to a draw because there might be no weakness to explored. However, the learning might be more challenging as the opponent (itself) might change ways of playing over time.\n",
    "\n",
    "## Ex 1.2\n",
    "Symmetries:\n",
    "We might take advantage of the symmetry by have a different way of representing states to reduce the state space. As many combinations of action + previous positions of the board will lead to the same board configurations, we can just use this final configurations to be the state. As the state space is less, the learning process my become better. \n",
    "\n",
    "## Ex 1.3\n",
    "Greedy play:\n",
    "If the RL player plays purely greedy, it only exploits. As a result, the policy might converge to sub-optimal policies. It will perform worse than a non-greedy player who has room for exploring the environment and might discover better strategies. The problems include: converging to sub-optimal policies as a result of incorrectly estimations of the state value, worse performance.\n",
    "\n",
    "## Ex 1.4\n",
    "Learning from exploration: \n",
    "Learning from exploratory moves with decaying step-size parameters are common in later chapters. Learning in this way would improve estimates of values of states prior exploratory moves as when skipping updates at moves of exploration, the values of these states will not be updated.\n",
    "\n",
    "## Ex 1.5\n",
    "Other improvements:\n",
    "1. Learning from all moves\n",
    "2. Reducing step-size over time to reducing less exploration near convergence\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
